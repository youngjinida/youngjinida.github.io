---
title:  "학습 관련 기술들 - 2" 

categories:
  - Basic
tags:
  - [Programming, Python]

toc: true
toc_sticky: true

date: 2022-04-11
last_modified_at: 2022-04-11
---

밑바닥부터 시작하는 딥러닝 책을 공부한 내용을 토대로 작성한 글입니다.

<br>

# Chapter 5. 학습 관련 기술 - 2

전 글에서는 최적값을 탐색하는 Optimizer, Weight Initialization, Batch Normalization 등에 대해서 알아보았다. 이번 글에서는 전 글에이어서 학습 관련 기술중에서도 오버피팅의 대응책인 가중치 감쇠, 드롭아웃 등에대해서 알아볼 예정이다.

## 5.1 오버피팅 

기계학습에서는 오버피팅이 문제가 되는 일이 많다. 여기서 오버피팅이란 신경망이 훈련 데이터에만 지나치게 적응되어 그 외의 데이터에는 제대로 대응하지 못하는 상태를 말하고 기계 학습은 범용 성능을 지향한다. 훈련 데이터에는 포함되지 않는 아직 보지 못한 데이터가 주어져도 바르게 식별해내는 모델이 바람직하며 복잡하고 표현력이 높은 모델을 만들수는 있지만 그만큼 오버피팅을 억제하는 기술이 중요해지게된다.

주로 오버피팅은 매개변수가 많고 표현력이 높은 모델을 사용할 때 또는 훈련 데이터가 적을 떄 발생한다. 보통 오버피팅이 발생할 때의 정확도 그래프는 다음과 같이 나타난다.

![img5-1](/assets/images/badak/fig%206-20.png)

훈련 데이터를 사용하여 측정한 정확도는 약 100epoch에서 부터 100%의 정확도를 보이지만 그러나 시험 데이터에 대해서는 낮은 정확도를 보이며 이처럼 정확도가 크게 벌어지는 것은 훈련 데이터에만 적응해버린 결과이며 훈련 때 사용하지 않은 범용(시험)데이터에는 제대로 대응하지 못하는 것을 이 그래프에서 확인할 수 있다.

이제 오버피팅을 억제하기 위해서 사용하는 방법을 소개한다.

## 5.2 가중치 감쇠

오버피팅 억제용으로 예로부터 많이 이용해온 방법 중 하나로는 <u>가중치 감쇠</u>가 있다. 이는 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 페널티를 부과하여 오버피팅을 억제하는 방법이다. 큰 가중치에 대해서 페널티를 부과하는 이유는 오버피팅이 발생할 때는 가중치 매개변수의 값이 너무 커서 발생하는 경우가 많기 때문이다.

이제 가중치 감쇠를 어떻게 설게하느냐인데 보통 사용하는 방법으로는 우리가 신경망을 학습시키는 척도로써 사용하는 손실 함수에 가중치의 2차 Norm을 더해줌으로써 가중치가 커지는 것을 억제하게 된다. 가중치를
$W$
라고한다면 가중치 감쇠항은
$\frac{1}{2}\lambda W^2$
이며 여기서
$\lambda$
는 정규화의 세기를 조절하는 하이퍼파라미터이다. 람다의 크기가 커질수록 큰 가중치에 대한 페널티가 커지게된다. 그리고 가중치의 기울기를 구하는 계산에서는 그동안의 오차역전파법에 따른 결과에 정규화 항을 미분한
$\lambda W$
를 더한다.

실험을 진행하는 코드는 다음과 같다. 여기서 사용하는 MultiLayerNet은 전 포스팅의 MultiLayerNet.py를 불러와서 진행하면 된다. 오버피팅을 의도적으로 일으키기 위해서 은닉층을 깊게하고 훈련 데이터를 줄여서 실험을 진행하였다.

```python
import numpy as np
import matplotlib.pyplot as plt

(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)

x_train = x_train[:300]
t_train = t_train[:300]

weight_decay_lambda = 0.1


network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10, weight_decay_lambda=weight_decay_lambda)

optimizer = SGD(lr=0.01)

max_epochs = 201
train_size = x_train.shape[0]
batch_size = 100

train_loss_list = []
train_acc_list = []
test_acc_list = []

iter_per_epoch = max(train_size / batch_size, 1)
epoch_cnt = 0

for i in range(1000000000):
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]

    grads = network.gradient(x_batch, t_batch)
    optimizer.update(network.params, grads)

    if i % iter_per_epoch == 0:
        train_acc = network.accuracy(x_train, t_train)
        test_acc = network.accuracy(x_test, t_test)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)

        print("epoch:" + str(epoch_cnt) + ", train acc:" + str(train_acc) + ", test acc:" + str(test_acc))

        epoch_cnt += 1
        if epoch_cnt >= max_epochs:
            break

markers = {'train': 'o', 'test': 's'}
x = np.arange(max_epochs)
plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)
plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)
plt.xlabel("epochs")
plt.ylabel("accuracy")
plt.ylim(0, 1.0)
plt.legend(loc='lower right')
plt.show()
```

아래 결과를 보면 훈련 데이터에 대한 정확도와 시험 데이터에 대한 정확도에는 여전히 차이가 있지만 가중치 감소를 이용하지않은 5.1 오버피팅의 예시와 비교하면 그 차이가 줄어든 것을 확인할 수 잇다. 다시말해 오버피팅이 억제되었다는 소리이다. 또한 훈련데이터의 정확도가 100%에 도달하지 못한 점도 주목해야할 부분이다.