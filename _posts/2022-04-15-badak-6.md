---
title:  "합성곱 신경망(CNN)" 

categories:
  - Basic
tags:
  - [Programming, Python]

toc: true
toc_sticky: true

date: 2022-04-14
last_modified_at: 2022-04-14
---

밑바닥부터 시작하는 딥러닝 책을 공부한 내용을 토대로 작성한 글입니다.

<br>

# Chapter 6. Convolution Neural Network

이번에 배울 CNN은 이미지 인식과 음성 인식 등 다양한 곳에서 사용되는데, 특히 이미지 인식 분야에서 딥러닝을 활용한 기법은 거의 다 CNN을 기초로한다. 이번엔 CNN의 이론을 살펴보고 파이썬으로 구현해보자.

## 6.1 CNN이란?

우선 CNN을 이해하기 위해서 네트워크 구조를 살펴보며 전체 틀을 이해해보자. CNN도 지금까지의 신경망과 같이 레고 블록처럼 계층을 조합하여 만들수 있다. 다만, 합성곱 계층(Convolution Layer)과 풀링 계층(Pooling Layer)이 새롭게 등장한다. 지금까지의 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있었는데 이를 완전연결 계층(Fully Connected Layer)이라고 하며 이러한 구조를 Affine 계층이라는 이름으로 구현했었다. 이 Affine 계층을 사용하면 가령 층이 5개인 완전연결 신경망은 아래와 같이 구현할 수 있다.

![img6-1](/assets/images/badak/fig%207-1.png)

위 그림과 같이 완전연결 신경망은 Affine 계층 뒤에 활성화 함수를 갖는 ReLU 계층이 이어지며 이 그림에서는  Affine-ReLU 조합이 4개가 있으며 마지막 5번째 층은 Affine 계층에 이어 소프트맥스 계층에서 최종 결과를 출력한다. 그럼 CNN의 구조는 어떻게 다를까? 아래 그림은 CNN의 예이다.

![img6-2](/assets/images/badak/fig%207-2.png)

CNN에서는 합성곱 계층과 풀링 계층이 추가된다. CNN의 계층은 보통 Conv-ReLU-Pooling의 흐름으로 연결되며 지금까지의 Affine-ReLU가 Conv-ReLU-Pooling으로 바뀌었다고 생각하면된다. 또한 CNN에서 주목할 점은 출력에 가까운 층에서는 지금까지의 Affine-ReLU의 구성을 사용할 수 있다는 것이다.

## 6.2 합성곱 계층

CNN에서는 패딩(padding), 스트라이드(stride)등 CNN 고유의 용어가 등장한다. 또, 각 계층 사이에는 3차원 데이터같이 입체적인 데이터가 흐른다는 점에서 완전연결 신경망과 다르다. 지금까지 본 완전연결 신경망에서는 완전연결 계층을 사용했다. 완전연결 계층에서는 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할 수 있다. 이러한 완전연결 계층의 문제점은 데이터의 형상이 무시된다는 것이다. 입력 데이터가 이미지인 경우를 예로 들면 이미지는 통상 세로, 가로, 채널로 구성된 3차원 데이터이다. 그러나 완전연결 계층에 입력할 때는 3차원 데이터를 평평한 1차원 데이터로 평탄화해줘야 한다.

이미지는 3차원 형상이며, 이 형상에는 소중한 공간적 정보가 담겨 있다. 예를 들어 공간적으로 가까운 픽셀은 값이 비슷하거나, RGB의 각 채널은 서로 밀접하게 관련되어 있거나, 거리가 먼 픽셀끼리는 별 연관이 없는 등, 3차원 속에서 의미를 갖는 본질적인 패턴이 숨어 있을 것입니다. 그러나 완전연결 계층은 형상을 무시하고 모든 입력 데이터를 동등한 뉴런으로 취급하여 형상에 담긴 정보를 살릴 수 없다.

한편, 합성공 계층은 형상을 유지하며 이미지도 3차원 데이터로 입력받으며, 마찬가지로 다음 계층에도 3차원 데이터로 전달한다. 그래서 CNN은 이미지처럼 형상을 가진 데이터를 제대로 이해할 수 있다.

또한 합성곱 계층의 입출력 데이터를 특징맵이라고 하며 합성곱 계층의 입력 데이터를 입력 특징맵, 출력 데이터를 출력 특징맵이라고 한다.

합성곱 계층에서는 합성곱 연산을 처리하며 합성곱 연산은 이미지 처리에서 사용하는 필터 연산에 해당한다. 아래의 그림들을 살펴보자

![img6-3](/assets/images/badak/fig%207-3.png)

![img6-4](/assets/images/badak/fig%207-4.png)

예와 같이 합성곱 연산은 입력데이터에 필터를 적용한다. 이 예에서 입력 데이터는 세로, 가로 방향의 형상을 가졌고 필터 역시 세로, 가로 방향의 차원을 가진다. 데이터와 필터의 형상을 높이, 너비로 표기하며 이 예에서는 입력은 (4, 4), 필터는 (3, 3), 출력은 (2, 2)가 된다. 문헌에 따라 필터를 커널이라고 칭하기도 한다. 합성곱 연산은 필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터에 적용한다. 여기서 말하는 윈도우란 회색 (3, 3) 부분을 가리키며 그림에서 보듯 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구한다. 그리고 그 결과를 출력의 해당 장소에 저장한다. 이 과정을 모든 장소에서 수행하면 합성곱 연산의 출력이 완성된다.

또한 완전 연결 신경망에는 가중치 매개변수와 편향이 존재하는데 CNN에서는 필터의 매개변수가 그동안의 가중치에 해당한다. 그리고 CNN에도 편향이 존재하며 앞의 예는 필터를 적용하는 단계까지만 보여준 것이며 편향까지 표현하면 아래와 같은 흐름이 된다.

![img6-5](/assets/images/badak/fig%207-5.png)

### 패딩

합성곱 연산을 수행하기 전 입력 데이터 주변을 특정 값으로 채우기도 한다. 이를 패딩이라고 하며 합성곱 연산에서 자주 이용하는 기법이다. 예를들어 아래 그림은 (4, 4) 크기의 입력 데이터에 폭이 1인 패딩을 적용한 모습이다.

![img6-6](/assets/images/badak/fig%207-6.png)

그림을 보면 처음에 크기가 (4, 4)이던 입력 데이터에 패딩이 추가되어 (6, 6)크기의 데이터가 된 것을 확인할 수 있다. 이 입력에 (3, 3) 크기의 필터를 걸면 (4, 4) 크기의 출력 데이터가 생성된다. 이 예에서는 패딩을 1로 설정했지만 2나 3등 원하는 정수로 설정할 수 있다.

### 스트라이드

필터를 적용하는 위치 간격을 스트라이드라고 한다. 지금까지 본 예는 모두 스트라이드가 1이었지만 예를들어 스트라이드를 2로 하면 필터를 적용하는 윈도우가 두 칸씩 이동한다. 아래는 스트라이드가 2인 예이다.

![img6-7](/assets/images/badak/fig%207-7.png)

위 그림에서는 크기가 (7, 7)인 입력 데이터에 스트라이드를 2로 설정한 필터를 적용한다. 이처럼 스트라이드는 필터를 적용하는 간격을 지정한다. 그런데 스트라이드를 2로 하니 출력이 (3, 3)으로 줄어든 것을 확인할 수 있다. 이처럼 스트라이드를 키우면 출력 크기는 작아진다. 한편, 패딩을 크게 하면 출력 크게하면 출력이 커진 것을 확인할 수 있다. 이런 관계를 수식화 하면 아래와 같다. 여기서 입력 크기는 (H, W), 필터 크기는 (FH, FW), 출력 크기는(OH, OW), 패딩을 P, 스트라이드는 S이다.

$$
OH = \frac{H+2P-FH}{S} + 1
$$

$$
OW = \frac{W+2P-FW}{S} + 1
$$

이 수식을 사용하여 입력이 (7, 7), 필터 (3, 3), 스트라이드가 2, 패딩이 0인 경우 계산을 해보자

$$
OH = \frac{7 + 2\cdot 0 - 3}{2} + 1 = 3
$$

$$
OW = \frac{7 + 2\cdot 0 - 3}{2} + 1 = 3
$$

이상의 예에서 처럼 단순히 값을 대입하기만 하면 출력 크기를 계한할 수 있다. 단, 위 수식이 정수로 나누어떨어져야 한다는 것에 주의해야한다.

## 6.3 3차원 데이터의 합성곱 연산

이번에는 3차원 데이터의 합성곱의 연산을 살펴보겠다. 아래 그림은 3차원 데이터의 합성곱 연산의 예이다. 2차원일때와 비교하면 채널 방향으로 특징 맵이 늘어난 것을 확인할 수 있으며 채널 쪽으로 특징 맵이 늘어났다. 채널 쪽으로 특징 맵이 여러 개 있다면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고 그 결과를 더해서 하나의 출력을 얻는다.

![img6-8](/assets/images/badak/fig%207-9.png)

3차원 합성곱 연산에서 주의할 점은 입력 데이터의 채널 수와 필터의 채널 수가 같아야 한다는 것이다. 이 예에서는 모두 3개로 일치한다. 하지만 필터 자체의 크기는 원하는 값으로 설정할 수 있다. 

3차원의 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 쉽다. 블록은 아래 그림과 같은 3차원 직육면체이다. 이 예에서는 출력 데이터는 한장의 특징 맵이다. 

![img6-9](/assets/images/badak/fig%207-10.png)

한장의 특징 맵을 다른 말로 하면 채널이 1개인 특징 맵이다. 그럼 합성곱 연산의 출력으로 다수의 채널을 내보내려면 어떻게 해야할까? 그 답은 필터를 다수 사용하는 것이다. 그림으로는 아래와 같다.

![img6-10](/assets/images/badak/fig%207-11.png)

이 그림과 같이 필터를 FN개 적용하면 출력 맵도 FN개가 생성된다. 그리고 FN개의 맵을 모으면 형상이 (FN, OH, OW)인 블록이 생성되며 이 완성된 블록을 다음 계층으로 넘기겠다는 것이 CNN의 처리흐름이다.

## 6.4 CNN에서의 배치 처리

완전연결 신경망을 구현하면서는 이 방식을 지원하여 처리 효율을 높이고 미니배치 방식의 학습도 지원하도록 했다. 합성곱 연산도 마찬가지로 배치 처리를 지원하고자 한다. 그래서 각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장한다. 구체적으로는 데이터를 (데이터 수, 채널 수, 높이, 너비) 순으로 저장한다. 데이터가 N개 일 때 배치 합성곱 연산의 처리 흐름이다.

![img6-11](/assets/images/badak/fig%207-12.png)

이처럼 데이터는 4차원 형상을 가진 채 각 계층을 타고 흐른다. 여기서 주의할 점으로는 신경망에 4차원 데이터가 하나 흐를 때마다 데이터 N개에 대한 합성곱 연산이 이루어진다는 것이며 즉, N회 분의 처리를 한 번에 수행하는 것이다.

## 6.5 풀링 계층

풀링은 세로, 가로 방향의 공간을 줄이는 연산이다. 예를들어 아래와 같이 2x2 영역을 원소 하나로 집약하여 공간 크기를 줄인다. 

![img6-12](/assets/images/badak/fig%207-13.png)

위의 Max Pooling의 예는 스트라이드 2로 처리하는 순서이며 최대 풀링은 최댓값을 구하는 연산으로 2x2는 대상 영역의 크기를 뜻한다. 즉 2x2 최대 풀링은 그림과 같이 2x2 크기의 영역에서 가장 큰 원소 하나를 꺼낸다. 또, 스트라이드는 이 예에서는 2로 설정 했으므로 2x2 윈도우가 원소 2칸 간격으로 이동한다. 참고로 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통이다.

이러한 풀링계층의 특징은 대상 영역에서 최댓값이나 평균을 취하는 명확한 처리이므로 특별히 학습할 것이 없다. 또한 채널 수가 변하지 않는다 폴링연산은 입력 데이터의 채널 수 그대로 출력 데이터를 내보낸다. 아래 그림과 같이 채널마다 독립적으로 계산하기 때문이다.

![img6-13](/assets/images/badak/fig%207-14.png)

마지막으로 입력의 변화에 영향을 적게받는다. 입력 데이터가 조금 변해도 풀링의 결과는 잘 변하지 않는다.

## 6.6 합성곱/풀링 게층 구현

합성곱 연산을 구현할 때 가장 쉽게 생각할 수 있는 방법은 for문 여러개를 사용하여 구현하는 것이다. 하지만 그렇게 계산을 하게 되면 Numpy에 for문을 사용하게 되는데 Numpy에 for문을 사용하면 성능이 떨어진다는 단점이 있다. 그러므로 im2col(col2im)을 사용하여 효율적으로 합성곱/풀링 연산을 구현해보자

### im2col

im2col은 입력 데이터를 계산하기 좋게 전개하는 함수이다. 아래 그림과 같이 3차원 입력 데이터에 im2col을 적용하면 2차원 행렬로 바꾸게된다. 구체적으로는 입력 데이터에서 필터를 적용하는 영역을 한줄로 늘어놓는다.
이 전개를 필터를 적용하는 모든 영역에서 수행하는게 im2col이다.

![img6-14](/assets/images/badak/fig%207-18.png)

위 그림에서는 보기에 좋게끔 스트라이드를 크게 잡아 필터의 적용 영역이 겹치지 않도록 했지만 실제 상황에서는 영역이 겹치는 경우가 대부분이다. 필터 적용 영역이 겹치게 되면 im2col로 전개한 후의 원소 수가 원래 블록의 원소수 보다 많아지게 된다. 그래서 im2col을 사용하면 메모리를 더 많이 소비하는 단점이 있다. 하지만 컴퓨터는 큰 행렬을 묶어서 계산하는 데 탁월하며 예를 들어 행렬 계산 라이브러리 등은 행렬 계산에 고도로 최적화되어 큰 행렬의 곱셈을 빠르게 계산할 수 있다. 그래서 문제를 행렬 계산으로 만들면 행렬계산 라이브러리를 활용해 효율을 높일 수 있다. 아래는 앞의 이론을 통해 배운 합성곱 계층의 구현 흐름과 구현한 im2col, col2im 함수이다. col2im은 역전파를 계산할 때 사용된다.

![img6-15](/assets/images/badak/fig%207-19.png)

```python
def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
        N, C, H, W = input_data.shape
        out_h = (H + 2 * pad - filter_h)//stride + 1
        out_w = (W + 2 * pad - filter_w)//stride + 1

        img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], 'constant')
        col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))

        for y in range(filter_h):
            y_max = y + stride * out_h
            for x in range(filter_w):
                x_max = x + stride * out_w
                col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]

        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)
        return col

def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
        N, C, H, W = input_data.shape
        out_h = (H + 2 * pad - filter_h)//stride + 1
        out_w = (W + 2 * pad - filter_w)//stride + 1

        img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad), (pad, pad)], 'constant')
        col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))

        for y in range(filter_h):
            y_max = y + stride * out_h
            for x in range(filter_w):
                x_max = x + stride * out_w
                col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]

        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)
        return col
```

### 합성곱 계층 구현

이제 위에서 작성한 im2col 함수를 이용해 Convolution Layer를 구현해보자.

```python
class Convolution:
    def __init__(self, W, b, stride = 1, pad = 0):
        self.W = W
        self.b = b
        self.stride = stride
        self.pad = pad

        self.x = None
        self.col = None
        self.col_W = None

        self.dW = None
        self.db = None

    def forward(self, x):
        FN, C, FH, FW = self.W.shape
        N, C, H, W = x.shape

        out_h = 1 + int((H + 2 * self.pad - FH) / self.stride)
        out_w = 1 + int((W + 2 * self.pad - FW) / self.stride)
        
        col = im2col(x, filter_h = FH, filter_w = FW, stride = self.stride, pad = self.pad)
        col_W = self.W.reshape(FN, -1).T

        out = col @ col_W + self.b
        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)

        self.x = x
        self.col = col
        self.col_W = col_W
        
        return out

    def backward(self, dout):
        FN, C, FH, FW = self.W.shape
        dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN)

        self.db = np.sum(dout, axis = 0)
        self.dW = np.dot(self.col.T, dout)
        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)

        dcol = np.dot(dout, self.col_W.T)
        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)

        return dx
```

합성곱 계층은 필터, 편향, 스트라이드, 패딩을 인수로 받아 초기화한다. 순전파를 할 때는 입력 데이터를 im2col로 전개하고 필터도 reshape을 사용해 2차원 배열로 전개한다. 그리고 이렇게 전개한 두 행렬의 곱을 구한다. 또한 합성곱 계층의 역전파에서는 col2im함수를 사용하여 역전파를 진행한다.

### 풀링 계층 구현

풀링 계층 구현도 합성곱 계층과 마찬가지로 im2col을 사용해 입력 데이터를 전개한다. 단, 풀링의 경우엔 채널 쪽이 독립적이라는 점이 합성곱 계층과는 다르다. 예는 다음과 같다.

![img6-16](/assets/images/badak/fig%207-22.png)

이상이 풀링 계층의 처리 흐름이다. 코드는 다음과 같다.

```python
class Pooling:
    def __init__(self, pool_h, pool_w, stride = 1, pad = 0):
        self.pool_h = pool_h
        self.pool_w = pool_w
        self.stride = stride

        self.x = None
        self.arg_max = None
    
    def forward(self, x):
        N, C, H, W = x.shape

        out_h = int(1 + (H - self.pool_h) / self.stride)
        out_w = int(1 + (W - self.pool_w) / self.stride)

        col = im2col(x, self.pool_h, self.pool_w, self.stride, 0)
        col = col.reshape(-1, self.pool_h * self.pool_w)

        arg_max = np.argmax(col, axis = 1)
        out = np.max(col, axis =1)
        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)
        
        self.x = x
        self.arg_max = arg_max

        return out

    def backward(self, dout):
        dout = dout.transpose(0, 2, 3, 1)

        pool_size = self.pool_h * self.pool_w
        dmax = np.zeros((dout.size, pool_size))
        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()
        dmax = dmax.reshape(dout.shape + (pool_size, ))

        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)
        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, 0)

        return dx
```

## 6.7 CNN 구현하기

여태까지 합성곱 계층, 풀링 계층을 구현했으니 이를 활용한 CNN을 구현을 구현할 것이다. 또한 구현한 CNN을 토대로 MNIST 데이터를 학습시켜보고 테스트하는 과정까지 한번에 보도록하자.

***DeepConvNet.py***
```python

import numpy as np
from collections import OrderedDict
import pickle

class DeepConvNet:
    def __init__(self, input_dim = (1, 28, 28), \
                    conv_param_1 = {'filter_num': 16, 'filter_size': 3, 'pad': 1, 'stride': 1},
                    conv_param_2 = {'filter_num': 16, 'filter_size': 3, 'pad': 1, 'stride': 1},
                    conv_param_3 = {'filter_num': 32, 'filter_size': 3, 'pad': 1, 'stride': 1},
                    conv_param_4 = {'filter_num': 32, 'filter_size': 3, 'pad': 2, 'stride': 1},
                    conv_param_5 = {'filter_num': 64, 'filter_size': 3, 'pad': 1, 'stride': 1},
                    conv_param_6 = {'filter_num': 64, 'filter_size': 3, 'pad': 1, 'stride': 1},
                    hidden_size = 50, output_size = 10):
        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])
        weight_init_scale = np.sqrt(2.0 / pre_node_nums)

        self.params = {}
        pre_channel_num = input_dim[0]
        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):
            self.params['W' + str(idx+1)] = weight_init_scale[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])
            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])
            pre_channel_num = conv_param['filter_num']
        
        self.params['W7'] = weight_init_scale[6] * np.random.randn(64*4*4, hidden_size)
        self.params['b7'] = np.zeros(hidden_size)

        self.params['W8'] = weight_init_scale[7] * np.random.randn(hidden_size, output_size)
        self.params['b8'] = np.zeros(output_size)


        self.layers = []
        self.layers.append(Convolution(self.params['W1'], self.params['b1'], 
                           conv_param_1['stride'], conv_param_1['pad']))
        self.layers.append(Relu())
        self.layers.append(Convolution(self.params['W2'], self.params['b2'], 
                           conv_param_2['stride'], conv_param_2['pad']))
        self.layers.append(Relu())
        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))
        self.layers.append(Convolution(self.params['W3'], self.params['b3'], 
                           conv_param_3['stride'], conv_param_3['pad']))
        self.layers.append(Relu())
        self.layers.append(Convolution(self.params['W4'], self.params['b4'],
                           conv_param_4['stride'], conv_param_4['pad']))
        self.layers.append(Relu())
        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))
        self.layers.append(Convolution(self.params['W5'], self.params['b5'],
                           conv_param_5['stride'], conv_param_5['pad']))
        self.layers.append(Relu())
        self.layers.append(Convolution(self.params['W6'], self.params['b6'],
                           conv_param_6['stride'], conv_param_6['pad']))
        self.layers.append(Relu())
        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))
        self.layers.append(Affine(self.params['W7'], self.params['b7']))
        self.layers.append(Relu())
        self.layers.append(Dropout(0.5))
        self.layers.append(Affine(self.params['W8'], self.params['b8']))
        self.layers.append(Dropout(0.5))

        self.lastlayer = SoftmaxWithLoss()

    def predict(self, x, train_flg = False):
        for layer in self.layers:
            if isinstance(layer, Dropout):
                x = layer.forward(x, train_flg)
            else:
                x = layer.forward(x)
        
        return x

    def loss(self, x, t):
        y = self.predict(x, train_flg=True)
        return self.lastlayer.forward(y, t)
    
    def accuracy(self, x, t, batch_size = 100):
        if t.ndim != 1:
            t = np.argmax(t, axis = 1)
        
        acc = 0.0

        for i in range(int(x.shape[0] / batch_size)):
            tx = x[i*batch_size:(i+1)*batch_size]
            tt = t[i*batch_size:(i+1)*batch_size]
            y = self.predict(tx, train_flg=False)
            y = np.argmax(y, axis = 1)
            acc += np.sum(y == tt)
        
        return acc / x.shape[0]
    
    def gradient(self, x, t):
        self.loss(x, t)

        dout = 1
        dout = self.lastlayer.backward(dout)
        
        tmp_layers = self.layers.copy()
        tmp_layers.reverse()

        for layer in tmp_layers:
            dout = layer.backward(dout)

        grads = {}

        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):
            grads['W' + str(i+1)] = self.layers[layer_idx].dW
            grads['b' + str(i+1)] = self.layers[layer_idx].db
        
        return grads
        
    def save_params(self, file_name="params.pkl"):
        params = {}
        for key, val in self.params.items():
            params[key] = val
        with open(file_name, 'wb') as f:
            pickle.dump(params, f)

    def load_params(self, file_name="params.pkl"):
        with open(file_name, 'rb') as f:
            params = pickle.load(f)
        for key, val in params.items():
            self.params[key] = val

        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):
            self.layers[layer_idx].W = self.params['W' + str(i+1)]
            self.layers[layer_idx].b = self.params['b' + str(i+1)]

```
***DeepConvNet_Train.py***
```python
from trainer import Trainer
from dataset.mnist import load_mnist
import matplotlib.pyplot as plt

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)

network = DeepConvNet()
trainer = Trainer(network, x_train, t_train, x_test, t_test,epoch=20, mini_batch_size=100,
            optimizer='Adam', optimizer_params={'lr': 0.001}, 
            evaluate_sample_num_per_epoch=1000)

trainer.train()
network.save_params("deep_conv.pkl")
print('save')
```

***DeepConvNet_Test.py***
```python
import numpy as np
from deep_convnet import DeepConvNet
from dataset.mnist import load_mnist


(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)

network = DeepConvNet()
network.load_params("deep_conv.pkl")

acc = 0.0
batch_size = 100

for i in range(int(x_test.shape[0] / batch_size)):
    tx = x_test[i*batch_size:(i+1)*batch_size]
    tt = t_test[i*batch_size:(i+1)*batch_size]
    y = network.predict(tx, train_flg=False)
    y = np.argmax(y, axis=1)
    acc += np.sum(y == tt)
acc = acc / x_test.shape[0]

print("Accuracy: {}".format(acc))    
```

```bash
Accuracy: 0.9952
```

## 6.8 마무리하며

이번 CNN 포스팅을 마지막으로 밑바닥부터 시작하는 딥러닝에 대한 포스팅이 끝나게 되었다. 현재 3번째 밑바닥을 읽고있지만 블로그를 통하여 포스팅을 하게되니 못봤던 부분도 보게되는거 같아 도움이되었다. 하지만 일주일이면 책 한 권분량을 다 적어낼 수 있을지 알았지만 예상 외로 3주라는 긴 시간이 걸렸다. 블로그하는 사람들은 대단한 거같다. 앞으로 해야할 일들을 정리하자면 여태 적었던 글들에 대해서 오타 수정 및 깃 허브 업로드가 남았고 포스팅 계획은 파이토치 튜토리얼, 딥 러닝 논문 구현, 밑바닥2 ,Gstreamer, Deepstream, TensorRT, 알고리즘, 수학 관련글, OpenCV 공부, Kaggle, 졸업 작품관련 포스팅 정도인거 같다. 적어놓고보니 올해안에 다 못할거같다............